{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import datetime as dt\n",
    "from pytz import timezone\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertory = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'ar41_for_ulb.csv'\n",
    "N = 2**13\n",
    "B = 2**6\n",
    "df = pd.read_csv(repertory+file, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add weather data to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get weather data from openweathermap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib.request import urlopen\n",
    "# import json\n",
    "# import csv\n",
    "# import time\n",
    "# import datetime\n",
    "\n",
    "\n",
    "# # Timestamp 1 january 2023 UTC  is\t1672531201\n",
    "# # Each hour, + 3600\n",
    "# # Each day, + 86400\n",
    "# # End, 15 september, UTC is 1694818801\n",
    "# # Duration : 258 days or 22287600 seconds\n",
    "# # Careful, changement d'heure happening in Belgium but not for UTC\n",
    "\n",
    "# file = 'csvWeather.csv'\n",
    "# with open(repertory+file,'w',newline='') as weather :\n",
    "#     writer = csv.writer(weather)\n",
    "#     # Write the columns names on the csv\n",
    "#     fields = ['date','time','temp','wind','humidity']\n",
    "#     writer.writerow(fields)\n",
    "#     # For Bxl, Gand and Bastogne, write temperature, wind speed and humidity for each hour and each day between 01/01/23 and 15/09/23\n",
    "#     for day in range(258):\n",
    "#         for hour in range(24):\n",
    "#             urlbx = 'https://history.openweathermap.org/data/2.5/history/city?lat=50.5&lon=4.20&start={}&cnt=1&appid=0ecabdca455f4f022ca58f1a5929a9b7'.format(1672531201+(day*86400)+(hour*3600))\n",
    "#             data = json.load(urlopen(urlbx))\n",
    "#             windspeed = data['list'][0]['wind']['speed']\n",
    "#             temp = data['list'][0]['main']['temp']\n",
    "#             humidity =  data['list'][0]['main']['humidity']\n",
    "#             dt = datetime.datetime.fromtimestamp(data['list'][0]['dt'])\n",
    "#             dt = str(dt).split()\n",
    "#             writer.writerow([dt[0],dt[1],temp,windspeed,humidity])\n",
    "\n",
    "#             urlgand = 'https://history.openweathermap.org/data/2.5/history/city?lat=51.03&lon=3.43&start={}&cnt=1&appid=0ecabdca455f4f022ca58f1a5929a9b7'.format(1672531201+(day*86400)+(hour*3600))\n",
    "#             data = json.load(urlopen(urlgand))\n",
    "#             windspeed = data['list'][0]['wind']['speed']\n",
    "#             temp = data['list'][0]['main']['temp']\n",
    "#             humidity =  data['list'][0]['main']['humidity']\n",
    "#             writer.writerow([dt[0],dt[1],temp,windspeed,humidity])\n",
    "\n",
    "#             urlbast = 'https://history.openweathermap.org/data/2.5/history/city?lat=50.0&lon=5.43&start={}&cnt=1&appid=0ecabdca455f4f022ca58f1a5929a9b7'.format(1672531201+(day*86400)+(hour*3600))\n",
    "#             data = json.load(urlopen(urlbast))\n",
    "#             windspeed = data['list'][0]['wind']['speed']\n",
    "#             temp = data['list'][0]['main']['temp']\n",
    "#             humidity =  data['list'][0]['main']['humidity']\n",
    "#             writer.writerow([dt[0],dt[1],temp,windspeed,humidity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine our dataset with weather data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the closest point to define which weather report is the most relevant \n",
    "def closest(point, locs):\n",
    "    close = 9e20\n",
    "    for j in locs :\n",
    "        dist = 0\n",
    "        for i in range (2) :\n",
    "            dist += (point[i]-j[i])**2\n",
    "        if np.sqrt(dist) < close :\n",
    "            close = np.sqrt(dist)\n",
    "            best = j\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathWeather = repertory+'csvWeather.csv'\n",
    "pathTrain = repertory+'ar41_for_ulb.csv'\n",
    "weather = pd.read_csv(pathWeather)\n",
    "train = pd.read_csv(pathTrain,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a series for each dataframe that contains the closest point of the 3 studied locations\n",
    "# We chose 3 different towns in Belgium based on their average temperatures. \n",
    "# One in the south, rather cold, one in the center and one in the north, rather warm.\n",
    "locs = [(50.5, 4.2),(51.0,3.43),(50.0,5.43)]\n",
    "weather['closest'] = list(zip(weather['lat'], weather['lon']))\n",
    "train['coord'] = list(zip(train['lat'], train['lon']))\n",
    "train['closest'] = train.apply(lambda row: closest(row['coord'],locs),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = train['timestamps_UTC'].str.split().str[0]\n",
    "train['time'] = train['timestamps_UTC'].str.split().str[1].str[:2]\n",
    "weather['time'] = pd.to_datetime(weather['time'], format='%H:%M:%S')\n",
    "weather['time'] = weather['time'].dt.hour.apply(lambda x: str(x).zfill(2))\n",
    "print(train.shape,weather.shape)\n",
    "final = pd.merge(train,weather,on=['time','date','closest'],how='inner')\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('final2.xlsx',engine='xlsxwriter') #TODO\n",
    "final2 = final[final['mapped_veh_id'] < 105]\n",
    "final2.to_excel(writer,sheet_name='sheet1')\n",
    "writer.close()\n",
    "final.to_csv(repertory+'trains_weather.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter impossible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv with weather data\n",
    "file = 'trains_weather.csv'\n",
    "N = 17679273\n",
    "df = pd.read_csv(repertory+file, sep=';')\n",
    "df.info()\n",
    "df = df.iloc[:, :-2].drop(df.columns[16:18], axis=1) #remove some useless columns (closest,lat_y,lon_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''use file to make fit & ruled_out through rule-based processing.\n",
    "fitting is not sorted by trains or by time'''\n",
    "\n",
    "def sep_temp_air(df) :\n",
    "    upper = 200\n",
    "    lower = -15 # Determine if it is an overflow (and should be removed) or not\n",
    "    high = (df[\"RS_E_InAirTemp_PC1\"] > upper) | (df['RS_E_InAirTemp_PC2'] > upper)\n",
    "    higher = df.copy()[high] #Getting only rows that show an upper error\n",
    "    higher['hta'] = True #Adding a column to indicate if there's an upper error\n",
    "\n",
    "    low = (df[\"RS_E_InAirTemp_PC1\"] < lower) | (df['RS_E_InAirTemp_PC2'] < lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['lta'] = True\n",
    "\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "def sep_temp_water(df) :\n",
    "    upper = 100\n",
    "    lower = -5 # Determine if it is an overflow (and should be removed) or not\n",
    "    high = (df[\"RS_E_WatTemp_PC1\"] > upper) | (df['RS_E_WatTemp_PC2'] > upper)\n",
    "    higher = df.copy()[high]\n",
    "    higher['htw'] = True\n",
    "    low = (df[\"RS_E_WatTemp_PC1\"] <= lower) | (df['RS_E_WatTemp_PC2'] <= lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['ltw'] = True\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "def sep_temp_oil(df) :\n",
    "    upper = 200\n",
    "    lower = -100 # Determine if it is an overflow (and should be removed) or not\n",
    "    high = (df[\"RS_T_OilTemp_PC1\"] > upper) | (df['RS_T_OilTemp_PC2'] > upper)\n",
    "    higher = df.copy()[high]\n",
    "    higher['hto'] = True\n",
    "    low = (df[\"RS_T_OilTemp_PC1\"] < lower) | (df['RS_T_OilTemp_PC2'] < lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['lto'] = True\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "def sep_rpm(df) :\n",
    "    upper = 3000\n",
    "    lower = -1\n",
    "    high = (df[\"RS_E_RPM_PC1\"] > upper) | (df['RS_E_RPM_PC2'] > upper)\n",
    "    higher = df.copy()[high]\n",
    "    higher['hrpm'] = True\n",
    "    low = (df[\"RS_E_RPM_PC1\"] < lower) | (df['RS_E_RPM_PC2'] < lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['lrpm'] = True\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "def sep_press(df) :\n",
    "    upper = 689\n",
    "    lower = 1 \n",
    "    high = (df[\"RS_E_OilPress_PC1\"] > upper) | (df['RS_E_OilPress_PC2'] > upper)\n",
    "    higher = df.copy()[high]\n",
    "    higher['hpress'] = True\n",
    "    low = (df[\"RS_E_OilPress_PC1\"] < lower) | (df['RS_E_OilPress_PC2'] < lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['lpress'] = True\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "file = 'trains_weather.csv'\n",
    "\n",
    "df = pd.read_csv(repertory+ file,sep=\";\",index_col=[0])   \n",
    "print(df.head())\n",
    "\n",
    "N = df.shape[0]\n",
    "df = df.dropna() #12000 NaN's in the PC2 columns\n",
    "print(\"Naaan : \", df.shape[0],N-df.shape[0])\n",
    "ruled_out = df.isna()\n",
    "\n",
    "\n",
    "fit,h,l = sep_temp_air(df)\n",
    "print(\"Temperature air : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = ruled_out.append(h)\n",
    "ruled_out = ruled_out.append(l)\n",
    "\n",
    "fit,h,l = sep_temp_oil(fit)\n",
    "print(\"Temperature oil : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = ruled_out.append(h)\n",
    "ruled_out = ruled_out.append(l)\n",
    "\n",
    "fit,h,l = sep_temp_water(fit)\n",
    "print(\"Temperature water : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = ruled_out.append(h)\n",
    "ruled_out = ruled_out.append(l)\n",
    "\n",
    "fit,h,l = sep_press(fit)\n",
    "print(\"Pressure : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = ruled_out.append(h)\n",
    "ruled_out = ruled_out.append(l)\n",
    "\n",
    "fit,h,l = sep_rpm(fit)\n",
    "print(\"RPM : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = ruled_out.append(h)\n",
    "ruled_out = ruled_out.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.to_csv(repertory+'fittingtst.csv',sep=';',index=False)\n",
    "ruled_out.to_csv(repertory+'ruled_outtst.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'fittingtst.csv'\n",
    "\n",
    "df = pd.read_csv(repertory+file, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize time difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert timezone\n",
    "df['timestamps_UTC'] = pd.to_datetime(df['timestamps_UTC'], utc=True)\n",
    "tzone = timezone('Europe/Paris')\n",
    "df['timestamps_UTC'] = df['timestamps_UTC'].dt.tz_convert(tzone)\n",
    "\n",
    "#remove nan\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "\n",
    "df = df.sort_values(by=['mapped_veh_id','timestamps_UTC'])\n",
    "time_diffs = df['timestamps_UTC'].diff().dt.total_seconds()\n",
    "\n",
    "custom_bins = np.concatenate([np.arange(0, 130, 1)])\n",
    "\n",
    "# Plot a histogram of the time differences with custom bin edges\n",
    "plt.hist(time_diffs, bins=custom_bins, edgecolor='black')\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel('Time Differences (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Time Differences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create time series by train and with regular interval of time between two consecutive timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by train_id and timestamps in chronological order\n",
    "df = df.sort_values(by=['mapped_veh_id','timestamps_UTC']).reset_index()\n",
    "\n",
    "# Convert timestamps to datetime objects\n",
    "df['timestamps_UTC'] = pd.to_datetime(df['timestamps_UTC'], utc=True)\n",
    "\n",
    "# Calculate time differences (T(n)) between consecutive samples and fill NaN with 0\n",
    "n_n1 = df['timestamps_UTC'].diff().dt.total_seconds()\n",
    "n_n1 = n_n1.to_frame(name='n_n1')\n",
    "n_n1 = n_n1.fillna(0)\n",
    "\n",
    "# Insert the calculated time differences as a new column 'n_n1' at position 3\n",
    "df.insert(3,'n_n1',n_n1)\n",
    "\n",
    "df2 = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vince\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index  Unnamed: 0.1  mapped_veh_id  n_n1            timestamps_UTC  \\\n",
      "0   10519630       5493376          102.0   0.0 2023-01-23 07:25:08+00:00   \n",
      "1   10519642       8969009          102.0   8.0 2023-01-23 07:25:16+00:00   \n",
      "2   10519662      13873566          102.0  21.0 2023-01-23 07:25:37+00:00   \n",
      "3   10519663      14994675          102.0   4.0 2023-01-23 07:25:41+00:00   \n",
      "4   10519656      11935795          102.0  29.0 2023-01-23 07:26:10+00:00   \n",
      "..       ...           ...            ...   ...                       ...   \n",
      "95  10539750       3691099          102.0   6.0 2023-01-23 14:52:14+00:00   \n",
      "96  10540524       8960631          102.0  54.0 2023-01-23 14:53:08+00:00   \n",
      "97  10539849       4395399          102.0   6.0 2023-01-23 14:53:14+00:00   \n",
      "98  10539500       2406388          102.0  55.0 2023-01-23 14:54:09+00:00   \n",
      "99  10541729      16102555          102.0   6.0 2023-01-23 14:54:15+00:00   \n",
      "\n",
      "        lat_x     lon_x  RS_E_InAirTemp_PC1  RS_E_InAirTemp_PC2  \\\n",
      "0   51.017864  3.769079                17.0                18.0   \n",
      "1   51.017875  3.769046                17.0                20.0   \n",
      "2   51.017208  3.770179                19.0                20.0   \n",
      "3   51.016916  3.771036                19.0                20.0   \n",
      "4   51.016503  3.772182                19.0                21.0   \n",
      "..        ...       ...                 ...                 ...   \n",
      "95  51.015739  3.774153                 6.0                12.0   \n",
      "96  51.015514  3.774711                 6.0                12.0   \n",
      "97  51.015749  3.774149                 6.0                12.0   \n",
      "98  51.015499  3.774702                 6.0                12.0   \n",
      "99  51.015740  3.774146                 6.0                12.0   \n",
      "\n",
      "    RS_E_OilPress_PC1  ...                    coord       closest        date  \\\n",
      "0               210.0  ...  (51.0178637, 3.7690786)  (51.0, 3.43)  2023-01-23   \n",
      "1               200.0  ...  (51.0178749, 3.7690464)  (51.0, 3.43)  2023-01-23   \n",
      "2               193.0  ...  (51.0172078, 3.7701787)  (51.0, 3.43)  2023-01-23   \n",
      "3               196.0  ...  (51.0169155, 3.7710357)  (51.0, 3.43)  2023-01-23   \n",
      "4               200.0  ...  (51.0165029, 3.7721823)  (51.0, 3.43)  2023-01-23   \n",
      "..                ...  ...                      ...           ...         ...   \n",
      "95              276.0  ...   (51.0157393, 3.774153)  (51.0, 3.43)  2023-01-23   \n",
      "96              269.0  ...  (51.0155138, 3.7747105)  (51.0, 3.43)  2023-01-23   \n",
      "97              276.0  ...  (51.0157493, 3.7741489)  (51.0, 3.43)  2023-01-23   \n",
      "98              269.0  ...  (51.0154994, 3.7747023)  (51.0, 3.43)  2023-01-23   \n",
      "99              269.0  ...  (51.0157403, 3.7741459)  (51.0, 3.43)  2023-01-23   \n",
      "\n",
      "    time    temp  wind  humidity lat_y lon_y bin_interval_time  \n",
      "0      7  274.73  2.76        91  51.0  3.43                 8  \n",
      "1      7  274.73  2.76        91  51.0  3.43                16  \n",
      "2      7  274.73  2.76        91  51.0  3.43                37  \n",
      "3      7  274.73  2.76        91  51.0  3.43                41  \n",
      "4      7  274.73  2.76        91  51.0  3.43                10  \n",
      "..   ...     ...   ...       ...   ...   ...               ...  \n",
      "95    14  276.90  4.75        82  51.0  3.43                14  \n",
      "96    14  276.90  4.75        82  51.0  3.43                 8  \n",
      "97    14  276.90  4.75        82  51.0  3.43                14  \n",
      "98    14  276.90  4.75        82  51.0  3.43                 9  \n",
      "99    14  276.90  4.75        82  51.0  3.43                15  \n",
      "\n",
      "[100 rows x 27 columns]\n",
      "    traj            timestamps_UTC  n_n1\n",
      "0      0 2023-01-23 07:25:08+00:00   0.0\n",
      "1      0 2023-01-23 07:25:16+00:00   8.0\n",
      "2      0 2023-01-23 07:25:37+00:00  21.0\n",
      "3      0 2023-01-23 07:25:41+00:00   4.0\n",
      "4      0 2023-01-23 07:26:10+00:00  29.0\n",
      "..   ...                       ...   ...\n",
      "95     1 2023-01-23 14:52:14+00:00   6.0\n",
      "96     1 2023-01-23 14:53:08+00:00  54.0\n",
      "97     1 2023-01-23 14:53:14+00:00   6.0\n",
      "98     1 2023-01-23 14:54:09+00:00  55.0\n",
      "99     1 2023-01-23 14:54:15+00:00   6.0\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "       index  Unnamed: 0.1  mapped_veh_id  n_n1            timestamps_UTC  \\\n",
      "0   10519630       5493376          102.0   0.0 2023-01-23 07:25:08+00:00   \n",
      "1   10519642       8969009          102.0   8.0 2023-01-23 07:25:16+00:00   \n",
      "2   10519662      13873566          102.0  21.0 2023-01-23 07:25:37+00:00   \n",
      "3   10519663      14994675          102.0   4.0 2023-01-23 07:25:41+00:00   \n",
      "4   10519656      11935795          102.0  29.0 2023-01-23 07:26:10+00:00   \n",
      "..       ...           ...            ...   ...                       ...   \n",
      "95  10539750       3691099          102.0   6.0 2023-01-23 14:52:14+00:00   \n",
      "96  10540524       8960631          102.0  54.0 2023-01-23 14:53:08+00:00   \n",
      "97  10539849       4395399          102.0   6.0 2023-01-23 14:53:14+00:00   \n",
      "98  10539500       2406388          102.0  55.0 2023-01-23 14:54:09+00:00   \n",
      "99  10541729      16102555          102.0   6.0 2023-01-23 14:54:15+00:00   \n",
      "\n",
      "        lat_x     lon_x  RS_E_InAirTemp_PC1  RS_E_InAirTemp_PC2  \\\n",
      "0   51.017864  3.769079                17.0                18.0   \n",
      "1   51.017875  3.769046                17.0                20.0   \n",
      "2   51.017208  3.770179                19.0                20.0   \n",
      "3   51.016916  3.771036                19.0                20.0   \n",
      "4   51.016503  3.772182                19.0                21.0   \n",
      "..        ...       ...                 ...                 ...   \n",
      "95  51.015739  3.774153                 6.0                12.0   \n",
      "96  51.015514  3.774711                 6.0                12.0   \n",
      "97  51.015749  3.774149                 6.0                12.0   \n",
      "98  51.015499  3.774702                 6.0                12.0   \n",
      "99  51.015740  3.774146                 6.0                12.0   \n",
      "\n",
      "    RS_E_OilPress_PC1  ...                    coord       closest        date  \\\n",
      "0               210.0  ...  (51.0178637, 3.7690786)  (51.0, 3.43)  2023-01-23   \n",
      "1               200.0  ...  (51.0178749, 3.7690464)  (51.0, 3.43)  2023-01-23   \n",
      "2               193.0  ...  (51.0172078, 3.7701787)  (51.0, 3.43)  2023-01-23   \n",
      "3               196.0  ...  (51.0169155, 3.7710357)  (51.0, 3.43)  2023-01-23   \n",
      "4               200.0  ...  (51.0165029, 3.7721823)  (51.0, 3.43)  2023-01-23   \n",
      "..                ...  ...                      ...           ...         ...   \n",
      "95              276.0  ...   (51.0157393, 3.774153)  (51.0, 3.43)  2023-01-23   \n",
      "96              269.0  ...  (51.0155138, 3.7747105)  (51.0, 3.43)  2023-01-23   \n",
      "97              276.0  ...  (51.0157493, 3.7741489)  (51.0, 3.43)  2023-01-23   \n",
      "98              269.0  ...  (51.0154994, 3.7747023)  (51.0, 3.43)  2023-01-23   \n",
      "99              269.0  ...  (51.0157403, 3.7741459)  (51.0, 3.43)  2023-01-23   \n",
      "\n",
      "    time    temp  wind  humidity lat_y lon_y bin_interval_time  \n",
      "0      7  274.73  2.76        91  51.0  3.43                 8  \n",
      "1      7  274.73  2.76        91  51.0  3.43                16  \n",
      "2      7  274.73  2.76        91  51.0  3.43                37  \n",
      "3      7  274.73  2.76        91  51.0  3.43                41  \n",
      "4      7  274.73  2.76        91  51.0  3.43                10  \n",
      "..   ...     ...   ...       ...   ...   ...               ...  \n",
      "95    14  276.90  4.75        82  51.0  3.43                14  \n",
      "96    14  276.90  4.75        82  51.0  3.43                 8  \n",
      "97    14  276.90  4.75        82  51.0  3.43                14  \n",
      "98    14  276.90  4.75        82  51.0  3.43                 9  \n",
      "99    14  276.90  4.75        82  51.0  3.43                15  \n",
      "\n",
      "[100 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import timezone\n",
    "\n",
    "now = pd.datetime.now(tz=pytz.UTC)\n",
    "\n",
    "\n",
    "# Convert the timestamps_UTC column to datetime objects\n",
    "df2['timestamps_UTC'] = pd.to_datetime(df2['timestamps_UTC'], errors='coerce')\n",
    "\n",
    "# Create a new column 'bin_interval_time' containing the seconds part\n",
    "df2['bin_interval_time'] = df2['timestamps_UTC'].dt.second\n",
    "\n",
    "print(df2.head(100))\n",
    "\n",
    "# Sort the DataFrame by train_id and timestamps again\n",
    "sortedByTrain2 = df2.sort_values(by=['mapped_veh_id','timestamps_UTC']).reset_index()\n",
    "\n",
    "# Convert timestamps to datetime objects\n",
    "sortedByTrain2['timestamps_UTC'] = pd.to_datetime(sortedByTrain2['timestamps_UTC'], utc=True)\n",
    "\n",
    "# Add a 'sequence_start' column based on time gaps greater than 150 seconds\n",
    "sortedByTrain2['sequence_start'] = sortedByTrain2['n_n1'] > 150 \n",
    "\n",
    "sortedByTrain2['traj'] = sortedByTrain2['sequence_start'].cumsum()\n",
    "\n",
    "sortedByTrain2 = sortedByTrain2.drop(['sequence_start','date','time'],axis = 1)\n",
    "\n",
    "print(sortedByTrain2[['traj','timestamps_UTC','n_n1']].head(100))\n",
    "\n",
    "sortedByTrain2['most_common_bin'] = sortedByTrain2.groupby('traj')['bin_interval_time'].transform(lambda x: x.mode().iloc[0])\n",
    "\n",
    "print(df2.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "sortedByTrain2 = sortedByTrain\n",
    "sortedByTrain2[\"diff_bin\"] = abs(sortedByTrain2[\"bin_interval_time\"] - sortedByTrain2[\"most_common_bin\"])\n",
    "\n",
    "tau = 10\n",
    "\n",
    "sortedByTrain2 = sortedByTrain2[sortedByTrain2[\"diff_bin\"] <= tau]\n",
    "\n",
    "sortedByTrain2.drop(\"n_n1\", inplace=True, axis = 1)\n",
    "\n",
    "# Calculate time differences (T(n)) between consecutive samples and fill NaN with 0\n",
    "n_n1 = sortedByTrain2['timestamps_UTC'].diff().dt.total_seconds()\n",
    "n_n1 = n_n1.to_frame(name='n_n1')\n",
    "n_n1 = n_n1.fillna(0)\n",
    "\n",
    "# Insert the calculated time differences as a new column 'n_n1' at position 3\n",
    "sortedByTrain2.insert(3,'n_n1',n_n1)\n",
    "\n",
    "sortedByTrain2 = sortedByTrain2[sortedByTrain2[\"n_n1\"] >= 2 * tau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16517984\n",
      "9466653\n"
     ]
    }
   ],
   "source": [
    "print(sortedByTrain.shape[0])\n",
    "print(sortedByTrain2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   timestamps_UTC   n_n1  bin_interval_time  most_common_bin\n",
      "7201940 2023-05-04 09:40:04+00:00  236.0                  4                8\n",
      "7201941 2023-05-04 09:41:04+00:00   60.0                  4                8\n",
      "7201942 2023-05-04 09:42:11+00:00   67.0                 11                8\n",
      "7201943 2023-05-04 09:43:05+00:00   54.0                  5                8\n",
      "7201944 2023-05-04 09:44:06+00:00   61.0                  6                8\n",
      "7201946 2023-05-04 09:45:07+00:00   61.0                  7                8\n",
      "7201948 2023-05-04 09:46:07+00:00   60.0                  7                8\n",
      "7201951 2023-05-04 09:50:11+00:00  244.0                 11                8\n",
      "7201952 2023-05-04 09:51:11+00:00   60.0                 11                8\n",
      "7201953 2023-05-04 09:52:11+00:00   60.0                 11                8\n",
      "7201954 2023-05-04 09:53:01+00:00   50.0                  1                8\n",
      "7201955 2023-05-04 09:54:04+00:00   63.0                  4                8\n",
      "7201959 2023-05-04 09:57:15+00:00  191.0                 15                8\n",
      "7201961 2023-05-04 09:58:07+00:00   52.0                  7                8\n",
      "7201963 2023-05-04 09:59:08+00:00   61.0                  8                8\n",
      "7201964 2023-05-04 10:00:02+00:00   54.0                  2                8\n",
      "7201966 2023-05-04 10:01:03+00:00   55.0                  3                8\n",
      "7201968 2023-05-04 10:02:03+00:00   55.0                  3                8\n",
      "7201970 2023-05-04 10:03:02+00:00   54.0                  2                8\n",
      "7201972 2023-05-04 10:04:03+00:00   52.0                  3                8\n",
      "7201974 2023-05-04 10:05:06+00:00   55.0                  6                8\n",
      "7201976 2023-05-04 10:06:07+00:00   55.0                  7                8\n",
      "7201978 2023-05-04 10:07:07+00:00   56.0                  7                8\n",
      "7201980 2023-05-04 10:08:07+00:00   56.0                  7                8\n",
      "7201982 2023-05-04 10:09:07+00:00   53.0                  7                8\n",
      "7201984 2023-05-04 10:10:00+00:00   46.0                  0                8\n",
      "7201986 2023-05-04 10:11:00+00:00   45.0                  0                8\n",
      "7201988 2023-05-04 10:12:00+00:00   45.0                  0                8\n",
      "7201990 2023-05-04 10:13:01+00:00   46.0                  1                8\n",
      "7201992 2023-05-04 10:14:00+00:00   52.0                  0                8\n"
     ]
    }
   ],
   "source": [
    "tmp = sortedByTrain2[sortedByTrain2[\"traj\"]==20100]\n",
    "print(tmp[[\"timestamps_UTC\", \"n_n1\", \"bin_interval_time\",\"most_common_bin\"]].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0                                16517982\n",
       "index                                  16517983\n",
       "Unnamed: 0.1                           17679269\n",
       "n_n1                                1.08894e+07\n",
       "mapped_veh_id                               197\n",
       "timestamps_UTC        2023-09-13 21:52:58+00:00\n",
       "lat_x                                   51.3029\n",
       "lon_x                                   6.57248\n",
       "RS_E_InAirTemp_PC1                           91\n",
       "RS_E_InAirTemp_PC2                           95\n",
       "RS_E_OilPress_PC1                           688\n",
       "RS_E_OilPress_PC2                           688\n",
       "RS_E_RPM_PC1                               2303\n",
       "RS_E_RPM_PC2                               2463\n",
       "RS_E_WatTemp_PC1                            100\n",
       "RS_E_WatTemp_PC2                            100\n",
       "RS_T_OilTemp_PC1                            127\n",
       "RS_T_OilTemp_PC2                            116\n",
       "coord                   (51.3028883, 4.3449666)\n",
       "closest                            (51.0, 3.43)\n",
       "temp                                     305.62\n",
       "wind                                      13.89\n",
       "humidity                                    100\n",
       "lat_y                                        51\n",
       "lon_y                                      5.43\n",
       "bin_interval_time                            59\n",
       "traj                                      47812\n",
       "most_common_bin                              59\n",
       "diff_bin                                     10\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedByTrain2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sortedByTrain2[sortedByTrain2[\"traj\"]==20200]\n",
    "print(tmp[[\"timestamps_UTC\", \"n_n1\", \"bin_interval_time\",\"most_common_bin\"]].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedByTrain2.to_csv('./result/clean1.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedByTrain2 = sortedByTrain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [level_0, index, Unnamed: 0.1, n_n1, mapped_veh_id, timestamps_UTC, lat_x, lon_x, RS_E_InAirTemp_PC1, RS_E_InAirTemp_PC2, RS_E_OilPress_PC1, RS_E_OilPress_PC2, RS_E_RPM_PC1, RS_E_RPM_PC2, RS_E_WatTemp_PC1, RS_E_WatTemp_PC2, RS_T_OilTemp_PC1, RS_T_OilTemp_PC2, coord, closest, temp, wind, humidity, lat_y, lon_y, bin_interval_time, traj, most_common_bin, diff_bin]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame(columns=sortedByTrain2.columns)\n",
    "print(df_final)\n",
    "global add \n",
    "add = -1 \n",
    "\n",
    "def gb_to_rows(gb) :\n",
    "    gb.apply(lambda w: addrow(w, df_final), axis=1)\n",
    "    progress_bar1.update(1)\n",
    "    \n",
    "def addrow(row, df_final) :\n",
    "    global add\n",
    "    for i in range(round(row['n_n1'] / 60) - 1): # to check\n",
    "        df_final.loc[add + i,'timestamps_UTC'] = row['timestamps_UTC'] + dt.timedelta(seconds=i * 60)\n",
    "        df_final.loc[add + i,'mapped_veh_id'] = row['mapped_veh_id']\n",
    "        df_final.loc[add + i,'traj'] = row['traj']\n",
    "        add -= 1\n",
    "\n",
    "progress_bar1.close()\n",
    "from tqdm import tqdm\n",
    "progress_bar1 = tqdm(total=len(sortedByTrain2['traj'].unique()), desc=\"Processing groups\")\n",
    "import datetime as dt\n",
    "sortedByTrain2.groupby('traj').apply(lambda z: gb_to_rows(z))\n",
    "progress_bar1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing groups:   0%|          | 0/47810 [01:39<?, ?it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    0\n",
      "Name: traj, dtype: int32\n",
      "8    1\n",
      "Name: traj, dtype: int32\n",
      "980    2\n",
      "Name: traj, dtype: int32\n",
      "991    3\n",
      "Name: traj, dtype: int32\n",
      "1892    4\n",
      "Name: traj, dtype: int32\n",
      "2026    5\n",
      "Name: traj, dtype: int32\n",
      "2032    6\n",
      "Name: traj, dtype: int32\n",
      "2052    7\n",
      "Name: traj, dtype: int32\n",
      "3670    8\n",
      "Name: traj, dtype: int32\n",
      "3672    9\n",
      "Name: traj, dtype: int32\n",
      "3681    10\n",
      "Name: traj, dtype: int32\n",
      "4107    11\n",
      "Name: traj, dtype: int32\n",
      "5613    12\n",
      "Name: traj, dtype: int32\n",
      "6511    13\n",
      "Name: traj, dtype: int32\n",
      "6531    14\n",
      "Name: traj, dtype: int32\n",
      "6582    15\n",
      "Name: traj, dtype: int32\n",
      "6590    16\n",
      "Name: traj, dtype: int32\n",
      "6609    17\n",
      "Name: traj, dtype: int32\n",
      "6639    18\n",
      "Name: traj, dtype: int32\n",
      "7065    19\n",
      "Name: traj, dtype: int32\n",
      "7942    20\n",
      "Name: traj, dtype: int32\n",
      "9283    21\n",
      "Name: traj, dtype: int32\n",
      "9816    22\n",
      "Name: traj, dtype: int32\n",
      "10175    23\n",
      "Name: traj, dtype: int32\n",
      "11045    24\n",
      "Name: traj, dtype: int32\n",
      "11049    25\n",
      "Name: traj, dtype: int32\n",
      "11560    26\n",
      "Name: traj, dtype: int32\n",
      "11756    27\n",
      "Name: traj, dtype: int32\n",
      "12115    28\n",
      "Name: traj, dtype: int32\n",
      "12326    29\n",
      "Name: traj, dtype: int32\n",
      "13254    30\n",
      "Name: traj, dtype: int32\n",
      "13265    31\n",
      "Name: traj, dtype: int32\n",
      "13273    32\n",
      "Name: traj, dtype: int32\n",
      "13632    33\n",
      "Name: traj, dtype: int32\n",
      "14595    34\n",
      "Name: traj, dtype: int32\n",
      "14948    35\n",
      "Name: traj, dtype: int32\n",
      "15335    36\n",
      "Name: traj, dtype: int32\n",
      "15740    37\n",
      "Name: traj, dtype: int32\n",
      "15760    38\n",
      "Name: traj, dtype: int32\n",
      "15920    39\n",
      "Name: traj, dtype: int32\n",
      "16076    40\n",
      "Name: traj, dtype: int32\n",
      "16371    41\n",
      "Name: traj, dtype: int32\n",
      "17109    42\n",
      "Name: traj, dtype: int32\n",
      "17270    43\n",
      "Name: traj, dtype: int32\n",
      "17704    44\n",
      "Name: traj, dtype: int32\n",
      "18233    45\n",
      "Name: traj, dtype: int32\n",
      "18249    46\n",
      "Name: traj, dtype: int32\n",
      "19328    47\n",
      "Name: traj, dtype: int32\n",
      "20322    48\n",
      "Name: traj, dtype: int32\n",
      "20447    49\n",
      "Name: traj, dtype: int32\n",
      "21239    50\n",
      "Name: traj, dtype: int32\n",
      "21243    51\n",
      "Name: traj, dtype: int32\n",
      "21959    52\n",
      "Name: traj, dtype: int32\n",
      "22914    53\n",
      "Name: traj, dtype: int32\n",
      "22916    54\n",
      "Name: traj, dtype: int32\n",
      "24255    55\n",
      "Name: traj, dtype: int32\n",
      "24872    56\n",
      "Name: traj, dtype: int32\n",
      "24880    57\n",
      "Name: traj, dtype: int32\n",
      "25055    58\n",
      "Name: traj, dtype: int32\n",
      "25104    59\n",
      "Name: traj, dtype: int32\n",
      "25136    60\n",
      "Name: traj, dtype: int32\n",
      "25154    61\n",
      "Name: traj, dtype: int32\n",
      "25199    62\n",
      "Name: traj, dtype: int32\n",
      "25204    63\n",
      "Name: traj, dtype: int32\n",
      "25206    64\n",
      "Name: traj, dtype: int32\n",
      "25238    65\n",
      "Name: traj, dtype: int32\n",
      "25279    66\n",
      "Name: traj, dtype: int32\n",
      "25363    67\n",
      "Name: traj, dtype: int32\n",
      "27356    68\n",
      "Name: traj, dtype: int32\n",
      "27371    69\n",
      "Name: traj, dtype: int32\n",
      "27392    70\n",
      "Name: traj, dtype: int32\n",
      "27787    71\n",
      "Name: traj, dtype: int32\n",
      "29223    72\n",
      "Name: traj, dtype: int32\n",
      "30100    73\n",
      "Name: traj, dtype: int32\n",
      "30655    74\n",
      "Name: traj, dtype: int32\n",
      "30879    75\n",
      "Name: traj, dtype: int32\n",
      "30882    76\n",
      "Name: traj, dtype: int32\n",
      "31485    77\n",
      "Name: traj, dtype: int32\n",
      "33943    78\n",
      "Name: traj, dtype: int32\n",
      "33952    79\n",
      "Name: traj, dtype: int32\n",
      "35940    80\n",
      "Name: traj, dtype: int32\n",
      "35946    81\n",
      "Name: traj, dtype: int32\n",
      "35949    82\n",
      "Name: traj, dtype: int32\n",
      "36260    83\n",
      "Name: traj, dtype: int32\n",
      "37299    84\n",
      "Name: traj, dtype: int32\n",
      "38123    85\n",
      "Name: traj, dtype: int32\n",
      "38552    86\n",
      "Name: traj, dtype: int32\n",
      "38896    87\n",
      "Name: traj, dtype: int32\n",
      "39072    88\n",
      "Name: traj, dtype: int32\n",
      "40324    89\n",
      "Name: traj, dtype: int32\n",
      "40522    90\n",
      "Name: traj, dtype: int32\n",
      "40596    91\n",
      "Name: traj, dtype: int32\n",
      "40942    92\n",
      "Name: traj, dtype: int32\n",
      "41470    93\n",
      "Name: traj, dtype: int32\n",
      "41523    94\n",
      "Name: traj, dtype: int32\n",
      "41969    95\n",
      "Name: traj, dtype: int32\n",
      "41993    96\n",
      "Name: traj, dtype: int32\n",
      "41998    97\n",
      "Name: traj, dtype: int32\n",
      "42508    98\n",
      "Name: traj, dtype: int32\n",
      "42555    99\n",
      "Name: traj, dtype: int32\n",
      "43208    100\n",
      "Name: traj, dtype: int32\n",
      "43629    101\n",
      "Name: traj, dtype: int32\n",
      "43653    102\n",
      "Name: traj, dtype: int32\n",
      "43718    103\n",
      "Name: traj, dtype: int32\n",
      "43734    104\n",
      "Name: traj, dtype: int32\n",
      "43737    105\n",
      "Name: traj, dtype: int32\n",
      "43757    106\n",
      "Name: traj, dtype: int32\n",
      "43758    107\n",
      "Name: traj, dtype: int32\n",
      "43760    108\n",
      "Name: traj, dtype: int32\n",
      "43857    109\n",
      "Name: traj, dtype: int32\n",
      "44368    110\n",
      "Name: traj, dtype: int32\n",
      "44407    111\n",
      "Name: traj, dtype: int32\n",
      "45209    112\n",
      "Name: traj, dtype: int32\n",
      "46139    113\n",
      "Name: traj, dtype: int32\n",
      "46165    114\n",
      "Name: traj, dtype: int32\n",
      "46580    115\n",
      "Name: traj, dtype: int32\n",
      "47195    116\n",
      "Name: traj, dtype: int32\n",
      "47243    117\n",
      "Name: traj, dtype: int32\n",
      "47247    118\n",
      "Name: traj, dtype: int32\n",
      "47267    119\n",
      "Name: traj, dtype: int32\n",
      "48362    120\n",
      "Name: traj, dtype: int32\n",
      "48903    121\n",
      "Name: traj, dtype: int32\n",
      "48921    122\n",
      "Name: traj, dtype: int32\n",
      "48946    123\n",
      "Name: traj, dtype: int32\n",
      "49812    124\n",
      "Name: traj, dtype: int32\n",
      "50573    125\n",
      "Name: traj, dtype: int32\n",
      "50584    126\n",
      "Name: traj, dtype: int32\n",
      "50626    127\n",
      "Name: traj, dtype: int32\n",
      "51338    128\n",
      "Name: traj, dtype: int32\n",
      "51771    129\n",
      "Name: traj, dtype: int32\n",
      "51778    130\n",
      "Name: traj, dtype: int32\n",
      "51825    131\n",
      "Name: traj, dtype: int32\n",
      "51853    132\n",
      "Name: traj, dtype: int32\n",
      "52332    133\n",
      "Name: traj, dtype: int32\n",
      "53200    134\n",
      "Name: traj, dtype: int32\n",
      "54898    135\n",
      "Name: traj, dtype: int32\n",
      "55341    136\n",
      "Name: traj, dtype: int32\n",
      "55458    137\n",
      "Name: traj, dtype: int32\n",
      "55493    138\n",
      "Name: traj, dtype: int32\n",
      "55494    139\n",
      "Name: traj, dtype: int32\n",
      "55585    140\n",
      "Name: traj, dtype: int32\n",
      "55877    141\n",
      "Name: traj, dtype: int32\n",
      "55988    142\n",
      "Name: traj, dtype: int32\n",
      "56138    143\n",
      "Name: traj, dtype: int32\n",
      "56423    144\n",
      "Name: traj, dtype: int32\n",
      "56425    145\n",
      "Name: traj, dtype: int32\n",
      "56487    146\n",
      "Name: traj, dtype: int32\n",
      "56867    147\n",
      "Name: traj, dtype: int32\n",
      "57684    148\n",
      "Name: traj, dtype: int32\n",
      "57688    149\n",
      "Name: traj, dtype: int32\n",
      "58203    150\n",
      "Name: traj, dtype: int32\n",
      "58395    151\n",
      "Name: traj, dtype: int32\n",
      "59002    152\n",
      "Name: traj, dtype: int32\n",
      "61350    153\n",
      "Name: traj, dtype: int32\n",
      "61400    154\n",
      "Name: traj, dtype: int32\n",
      "63668    155\n",
      "Name: traj, dtype: int32\n",
      "63682    156\n",
      "Name: traj, dtype: int32\n",
      "63688    157\n",
      "Name: traj, dtype: int32\n",
      "63742    158\n",
      "Name: traj, dtype: int32\n",
      "65857    159\n",
      "Name: traj, dtype: int32\n",
      "66841    160\n",
      "Name: traj, dtype: int32\n",
      "66949    161\n",
      "Name: traj, dtype: int32\n",
      "67732    162\n",
      "Name: traj, dtype: int32\n",
      "68621    163\n",
      "Name: traj, dtype: int32\n",
      "70035    164\n",
      "Name: traj, dtype: int32\n",
      "70568    165\n",
      "Name: traj, dtype: int32\n",
      "70776    166\n",
      "Name: traj, dtype: int32\n",
      "71234    167\n",
      "Name: traj, dtype: int32\n",
      "73626    168\n",
      "Name: traj, dtype: int32\n",
      "73672    169\n",
      "Name: traj, dtype: int32\n",
      "75981    170\n",
      "Name: traj, dtype: int32\n",
      "75984    171\n",
      "Name: traj, dtype: int32\n",
      "75990    172\n",
      "Name: traj, dtype: int32\n",
      "75998    173\n",
      "Name: traj, dtype: int32\n",
      "76003    174\n",
      "Name: traj, dtype: int32\n",
      "76633    175\n",
      "Name: traj, dtype: int32\n",
      "77494    176\n",
      "Name: traj, dtype: int32\n",
      "79389    177\n",
      "Name: traj, dtype: int32\n",
      "79429    178\n",
      "Name: traj, dtype: int32\n",
      "79445    179\n",
      "Name: traj, dtype: int32\n",
      "79497    180\n",
      "Name: traj, dtype: int32\n",
      "79523    181\n",
      "Name: traj, dtype: int32\n",
      "79874    182\n",
      "Name: traj, dtype: int32\n",
      "79895    183\n",
      "Name: traj, dtype: int32\n",
      "79992    184\n",
      "Name: traj, dtype: int32\n",
      "82347    185\n",
      "Name: traj, dtype: int32\n",
      "82417    186\n",
      "Name: traj, dtype: int32\n",
      "82956    187\n",
      "Name: traj, dtype: int32\n",
      "84857    188\n",
      "Name: traj, dtype: int32\n",
      "85716    189\n",
      "Name: traj, dtype: int32\n",
      "87042    190\n",
      "Name: traj, dtype: int32\n",
      "87894    191\n",
      "Name: traj, dtype: int32\n",
      "87897    192\n",
      "Name: traj, dtype: int32\n",
      "88081    193\n",
      "Name: traj, dtype: int32\n",
      "88420    194\n",
      "Name: traj, dtype: int32\n",
      "88895    195\n",
      "Name: traj, dtype: int32\n",
      "89079    196\n",
      "Name: traj, dtype: int32\n",
      "90909    197\n",
      "Name: traj, dtype: int32\n",
      "90951    198\n",
      "Name: traj, dtype: int32\n",
      "91000    199\n",
      "Name: traj, dtype: int32\n",
      "91641    200\n",
      "Name: traj, dtype: int32\n",
      "92003    201\n",
      "Name: traj, dtype: int32\n",
      "92206    202\n",
      "Name: traj, dtype: int32\n",
      "92248    203\n",
      "Name: traj, dtype: int32\n",
      "94114    204\n",
      "Name: traj, dtype: int32\n",
      "94673    205\n",
      "Name: traj, dtype: int32\n",
      "94860    206\n",
      "Name: traj, dtype: int32\n",
      "95419    207\n",
      "Name: traj, dtype: int32\n",
      "97324    208\n",
      "Name: traj, dtype: int32\n",
      "97352    209\n",
      "Name: traj, dtype: int32\n",
      "97361    210\n",
      "Name: traj, dtype: int32\n",
      "97384    211\n",
      "Name: traj, dtype: int32\n",
      "97395    212\n",
      "Name: traj, dtype: int32\n",
      "97588    213\n",
      "Name: traj, dtype: int32\n",
      "97630    214\n",
      "Name: traj, dtype: int32\n",
      "97631    215\n",
      "Name: traj, dtype: int32\n",
      "97840    216\n",
      "Name: traj, dtype: int32\n",
      "97900    217\n",
      "Name: traj, dtype: int32\n",
      "97902    218\n",
      "Name: traj, dtype: int32\n",
      "97980    219\n",
      "Name: traj, dtype: int32\n",
      "98040    220\n",
      "Name: traj, dtype: int32\n",
      "98180    221\n",
      "Name: traj, dtype: int32\n",
      "98216    222\n",
      "Name: traj, dtype: int32\n",
      "98226    223\n",
      "Name: traj, dtype: int32\n",
      "98231    224\n",
      "Name: traj, dtype: int32\n",
      "99513    225\n",
      "Name: traj, dtype: int32\n",
      "99546    226\n",
      "Name: traj, dtype: int32\n",
      "100060    227\n",
      "Name: traj, dtype: int32\n",
      "100441    228\n",
      "Name: traj, dtype: int32\n",
      "101299    229\n",
      "Name: traj, dtype: int32\n",
      "101980    230\n",
      "Name: traj, dtype: int32\n",
      "104397    231\n",
      "Name: traj, dtype: int32\n",
      "104400    232\n",
      "Name: traj, dtype: int32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10340\\1889705710.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msortedByTrain3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msortedByTrain2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msortedByTrain2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'traj'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgb_to_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode.chained_assignment\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m                 \u001b[1;31m# gh-20949\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f, data)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \"\"\"\n\u001b[1;32m--> 892\u001b[1;33m         \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;31m# group might be modified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10340\\1889705710.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msortedByTrain3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msortedByTrain2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msortedByTrain2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'traj'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgb_to_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10340\\1992435027.py\u001b[0m in \u001b[0;36mgb_to_rows\u001b[1;34m(gb)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgb_to_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maddrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'traj'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7551\u001b[0m         )\n\u001b[1;32m-> 7552\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7554\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m                     \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                         \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10340\\1992435027.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgb_to_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maddrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'traj'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10340\\1992435027.py\u001b[0m in \u001b[0;36maddrow\u001b[1;34m(row, df_final)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_n1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# to check\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mdf_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0madd\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'timestamps_UTC'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamps_UTC'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mdf_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0madd\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mapped_veh_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mapped_veh_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mdf_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0madd\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'traj'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'traj'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1609\u001b[0m                     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1610\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1611\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1612\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mkind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4034\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"axis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4035\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4036\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4038\u001b[0m     def drop(\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4462\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4463\u001b[0m         return self._reindex_axes(\n\u001b[1;32m-> 4464\u001b[1;33m             \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4465\u001b[0m         ).__finalize__(self, method=\"reindex\")\n\u001b[0;32m   4466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   3881\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3882\u001b[0m             frame = frame._reindex_index(\n\u001b[1;32m-> 3883\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3884\u001b[0m             )\n\u001b[0;32m   3885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   3897\u001b[0m     ):\n\u001b[0;32m   3898\u001b[0m         new_index, indexer = self.index.reindex(\n\u001b[1;32m-> 3899\u001b[1;33m             \u001b[0mnew_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3900\u001b[0m         )\n\u001b[0;32m   3901\u001b[0m         return self._reindex_with_indexers(\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   3336\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"is_overlapping\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3337\u001b[0m                     indexer = self.get_indexer(\n\u001b[1;32m-> 3338\u001b[1;33m                         \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3339\u001b[0m                     )\n\u001b[0;32m   3340\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3007\u001b[0m                 )\n\u001b[0;32m   3008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3009\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_engine_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3011\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.lookup\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vince\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'numpy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \"\"\"Convert the input to an array.\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sortedByTrain3 = sortedByTrain2\n",
    "import datetime as dt\n",
    "sortedByTrain2.groupby('traj').apply(lambda z: gb_to_rows(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sortedByTrain2[sortedByTrain2[\"traj\"]==20200]\n",
    "print(tmp[[\"timestamps_UTC\", \"n_n1\", \"bin_interval_time\",\"most_common_bin\"]].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sortedByTrain2[sortedByTrain2[\"traj\"]==20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedByTrain2 = df3\n",
    "tau = 12\n",
    "print(sortedByTrain2.head(100))\n",
    "sortedByTrain2 = sortedByTrain2[((sortedByTrain2['n_n1'] >= 60-tau) & (sortedByTrain2['n_n1'] <= 60+tau)) | (sortedByTrain2['n_n1'] >= 120-tau) & (sortedByTrain2['n_n1'] <= 120+tau)]\n",
    "print(sortedByTrain2.head(100))\n",
    "sortedByTrain2.drop(\"n_n1\", axis = 1,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sortedByTrain2[['traj','timestamps_UTC','n_n1','bin_interval_time','most_common_bin']].head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drop time intervals \n",
    "tau = 12\n",
    "print(df.head(100))\n",
    "df = df[((df['n_n1'] >= 60-tau) & (df['n_n1'] <= 60+tau)) | (df['n_n1'] >= 120-tau) & (df['n_n1'] <= 120+tau)]\n",
    "print(df.head(100))\n",
    "df.drop(\"n_n1\", axis = 1,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by train_id and timestamps again\n",
    "sortedByTrain = df.sort_values(by=['mapped_veh_id','timestamps_UTC']).reset_index()\n",
    "\n",
    "# Convert timestamps to datetime objects\n",
    "sortedByTrain['timestamps_UTC'] = pd.to_datetime(sortedByTrain['timestamps_UTC'], utc=True)\n",
    "\n",
    "# Calculate time differences (T(n)) between consecutive samples and fill NaN with 0\n",
    "n_n1 = sortedByTrain['timestamps_UTC'].diff().dt.total_seconds()\n",
    "n_n1 = n_n1.to_frame(name='n_n1')\n",
    "n_n1 = n_n1.fillna(0)\n",
    "\n",
    "# Insert the calculated time differences as a new column 'n_n1' at position 3\n",
    "sortedByTrain.insert(3,'n_n1',n_n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'sequence_start' column based on time gaps greater than 150 seconds\n",
    "sortedByTrain['sequence_start'] = sortedByTrain['timestamps_UTC'].diff().dt.total_seconds() > 150  #Can we not use the n__n1 column?\n",
    "\n",
    "sortedByTrain['traj'] = sortedByTrain['sequence_start'].cumsum()\n",
    "print(sortedByTrain['traj'].drop_duplicates())\n",
    "sortedByTrain = sortedByTrain.drop(['sequence_start','date','time'],axis = 1)\n",
    "\n",
    "print(sortedByTrain[['traj','timestamps_UTC','n_n1']].head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sortedByTrain[['traj','timestamps_UTC','n_n1']].head(502))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(columns=sortedByTrain.columns)\n",
    "print(df3)\n",
    "global add \n",
    "add = -1 \n",
    "\n",
    "def gb_to_rows(gb) :\n",
    "    gb.apply(lambda w: addrow(w,df3),axis=1)\n",
    "    print(gb['traj'].drop_duplicates())\n",
    "def addrow(row,df3) :\n",
    "    global add\n",
    "    if row['n_n1'] > 90 :\n",
    "        df3.loc[add,'timestamps_UTC'] = row['timestamps_UTC'] + dt.timedelta(seconds=60)\n",
    "        df3.loc[add,'mapped_veh_id'] = row['mapped_veh_id']\n",
    "        df3.loc[add,'traj'] = row['traj']\n",
    "        add -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "sortedByTrain.groupby('traj').apply(lambda z: gb_to_rows(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.shape)\n",
    "df = pd.concat([sortedByTrain,df3])\n",
    "print(sortedByTrain.shape)\n",
    "print(df.shape)\n",
    "df=df.interpolate()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedByTrain.to_csv(dirpath/'trajets_train.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedByTrain = sortedByTrain[['mapped_veh_id','timestamps_UTC','traj']]\n",
    "meantrajlength = sortedByTrain.groupby('traj').count().agg('mean')\n",
    "print(meantrajlength)\n",
    "print(sortedByTrain[sortedByTrain['traj'] == 183182])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting + drop na\n",
    "# Conversion du fuseau horaire\n",
    "df['timestamps_UTC'] = pd.to_datetime(df['timestamps_UTC'], utc=True)\n",
    "tzone = timezone('Europe/Paris')\n",
    "df['timestamps_UTC'] = df['timestamps_UTC'].dt.tz_convert(tzone)\n",
    "\n",
    "# Suppression des valeurs manquantes\n",
    "df = df.dropna()\n",
    "\n",
    "# Tri du DataFrame par 'mapped_veh_id' puis 'timestamps_UTC'\n",
    "df = df.sort_values(by=['mapped_veh_id', 'timestamps_UTC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of time series (we consider a new time series when, between two timestamps, the train change or the difference of time is greater than 10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize variables\n",
    "time_series_list = []\n",
    "current_time_series = []\n",
    "current_time_series.append(df.head(1))\n",
    "\n",
    "# Use tqdm to add a progress bar\n",
    "for i in tqdm(range(1, len(df)), desc=\"Processing Rows\", unit=\" row\"):\n",
    "    # Check if it's the same train\n",
    "    if df['mapped_veh_id'].iloc[i] == df['mapped_veh_id'].iloc[i - 1]:\n",
    "        # Calculate time difference in seconds\n",
    "        time_diff = (df['timestamps_UTC'].iloc[i] - df['timestamps_UTC'].iloc[i - 1]).total_seconds()\n",
    "\n",
    "        # Check for gaps greater than 5 minutes\n",
    "        if time_diff > 300:\n",
    "            # If gap is too large, start a new time series\n",
    "            if current_time_series:\n",
    "                time_series_list.append(current_time_series)\n",
    "            current_time_series = []\n",
    "        else:\n",
    "            current_time_series.append(df.iloc(i))\n",
    "    # Create new time series if it is a new train\n",
    "    else : \n",
    "        if current_time_series:\n",
    "            time_series_list.append(current_time_series)\n",
    "        current_time_series = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytz import timezone\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "# sorting + drop na\n",
    "# Conversion du fuseau horaire\n",
    "df['timestamps_UTC'] = pd.to_datetime(df['timestamps_UTC'], utc=True)\n",
    "tzone = timezone('Europe/Paris')\n",
    "df['timestamps_UTC'] = df['timestamps_UTC'].dt.tz_convert(tzone)\n",
    "\n",
    "# Suppression des valeurs manquantes\n",
    "df = df.dropna()\n",
    "\n",
    "# Tri du DataFrame par 'mapped_veh_id' puis 'timestamps_UTC'\n",
    "df = df.sort_values(by=['mapped_veh_id', 'timestamps_UTC'])\n",
    "\n",
    "# Initialize variables\n",
    "time_series_list = []\n",
    "current_time_series = []\n",
    "current_time_series.append(df.head(1))\n",
    "\n",
    "# Iterate over possible starting points (offsets)\n",
    "max_timestamps = 0\n",
    "best_offset = 0\n",
    "\n",
    "for offset in tqdm(range(60), desc=\"Searching for Best Offset\", unit=\"second\"):\n",
    "    current_time_series = []\n",
    "    current_time_series.append(df.head(1))\n",
    "\n",
    "    # Use tqdm to add a progress bar\n",
    "    for i in range(1, len(df)):\n",
    "        # Calculate time difference in seconds with the offset\n",
    "        time_diff = (df['timestamps_UTC'].iloc[i] - df['timestamps_UTC'].iloc[i - 1]).total_seconds() + offset\n",
    "\n",
    "        # Check for gaps greater than 60 seconds\n",
    "        if time_diff > 60:\n",
    "            # If gap is too large, start a new time series\n",
    "            if current_time_series:\n",
    "                time_series_list.append(current_time_series)\n",
    "            current_time_series = []\n",
    "        else:\n",
    "            current_time_series.append(df.iloc[i])\n",
    "\n",
    "    # Create new time series if it is a new train\n",
    "    if current_time_series:\n",
    "        time_series_list.append(current_time_series)\n",
    "\n",
    "    # Update best offset if the current offset gives more timestamps\n",
    "    if len(current_time_series) > max_timestamps:\n",
    "        max_timestamps = len(current_time_series)\n",
    "        best_offset = offset\n",
    "\n",
    "print(f\"Best Offset: {best_offset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_series in time_series_list:\n",
    "    for i in range(0, 59):\n",
    "        \n",
    "        for df_chunk in time_series:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and sort dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_temp_air(df) :\n",
    "    upper = 80\n",
    "    lower = 0 # Determine if it is an overflow (and should be removed) or not\n",
    "    high = (df[\"RS_E_InAirTemp_PC1\"] > upper) | (df['RS_E_InAirTemp_PC2'] > upper)\n",
    "    higher = df.copy()[high] #Getting only rows that show an upper error\n",
    "    higher['hta'] = True #Adding a column to indicate if there's an upper error\n",
    "\n",
    "    low = (df[\"RS_E_InAirTemp_PC1\"] < lower) | (df['RS_E_InAirTemp_PC2'] < lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['lta'] = True\n",
    "\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "def sep_temp_water(df) :\n",
    "    upper = 100\n",
    "    lower = 0 # Determine if it is an overflow (and should be removed) or not\n",
    "    high = (df[\"RS_E_WatTemp_PC1\"] > upper) | (df['RS_E_WatTemp_PC2'] > upper)\n",
    "    higher = df.copy()[high]\n",
    "    higher['htw'] = True\n",
    "    low = (df[\"RS_E_WatTemp_PC1\"] <= lower) | (df['RS_E_WatTemp_PC2'] <= lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['ltw'] = True\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "def sep_temp_oil(df) :\n",
    "    upper = 100\n",
    "    lower = 0 # Determine if it is an overflow (and should be removed) or not\n",
    "    high = (df[\"RS_T_OilTemp_PC1\"] > upper) | (df['RS_T_OilTemp_PC2'] > upper)\n",
    "    higher = df.copy()[high]\n",
    "    higher['hto'] = True\n",
    "    low = (df[\"RS_T_OilTemp_PC1\"] < lower) | (df['RS_T_OilTemp_PC2'] < lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['lto'] = True\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "def sep_rpm(df) :\n",
    "    upper = 3000\n",
    "    lower = 0\n",
    "    high = (df[\"RS_E_RPM_PC1\"] > upper) | (df['RS_E_RPM_PC2'] > upper)\n",
    "    higher = df.copy()[high]\n",
    "    higher['hrpm'] = True\n",
    "    low = (df[\"RS_E_RPM_PC1\"] < lower) | (df['RS_E_RPM_PC2'] < lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['lrpm'] = True\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "def sep_press(df) :\n",
    "    upper = 600\n",
    "    lower = 100 \n",
    "    high = (df[\"RS_E_OilPress_PC1\"] > upper) | (df['RS_E_OilPress_PC2'] > upper)\n",
    "    higher = df.copy()[high]\n",
    "    higher['hpress'] = True\n",
    "    low = (df[\"RS_E_OilPress_PC1\"] < lower) | (df['RS_E_OilPress_PC2'] < lower)\n",
    "    lower = df.copy()[low]\n",
    "    lower['lpress'] = True\n",
    "    fitting = df[~(high | low)]\n",
    "    return fitting, higher, lower\n",
    "\n",
    "\n",
    "def sep_cap_diff(df) :\n",
    "    column_name=df.columns[4:]\n",
    "    sensor_columns = column_name\n",
    "    sensor_columnsPC1 = sensor_columns[::2]\n",
    "    sensor_columnsPC2 = sensor_columns[1::2]\n",
    "    reldiff = 0.5\n",
    "    diff = pd.DataFrame()\n",
    "    allzero = pd.DataFrame()\n",
    "    fitting = df.copy()\n",
    "    for i in range(len(sensor_columnsPC1)):    \n",
    "        close = (np.isclose(fitting[sensor_columnsPC1[i]], \\\n",
    "                           fitting[sensor_columnsPC2[i]], rtol=reldiff) & (fitting[sensor_columnsPC1[i]] != 0) & (fitting[sensor_columnsPC2[i]] != 0))\n",
    "        invalid = ((fitting[sensor_columnsPC1[i]] == 0) & (fitting[sensor_columnsPC2[i]] == 0))\n",
    "        diff = diff._append(fitting[~close])\n",
    "        allzero = allzero._append(fitting[invalid])\n",
    "        fitting = fitting[close & ~invalid]\n",
    "        print(\"dshape : \",  diff.shape)\n",
    "    diff['different'] = True\n",
    "    allzero['allzero'] = True\n",
    "    return fitting, diff, allzero\n",
    "    \n",
    "df = pd.read_csv(file,sep=\";\",index_col=[0])   \n",
    "print(df.head())\n",
    "\n",
    "\n",
    "fit,h,l = sep_temp_air(df)\n",
    "print(\"Temperature air : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = h\n",
    "ruled_out = ruled_out._append(l)\n",
    "\n",
    "fit,h,l = sep_temp_oil(fit)\n",
    "print(\"Temperature oil : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = ruled_out._append(h)\n",
    "ruled_out = ruled_out._append(l)\n",
    "\n",
    "fit,h,l = sep_temp_water(fit)\n",
    "print(\"Temperature water : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = ruled_out._append(h)\n",
    "ruled_out = ruled_out._append(l)\n",
    "\n",
    "fit,h,l = sep_press(fit)\n",
    "print(\"Pressure : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = ruled_out._append(h)\n",
    "ruled_out = ruled_out._append(l)\n",
    "\n",
    "fit,h,l = sep_rpm(fit)\n",
    "print(\"RPM : \", fit.shape, h.shape, l.shape)\n",
    "ruled_out = ruled_out._append(h)\n",
    "ruled_out = ruled_out._append(l)\n",
    "\n",
    "\n",
    "fit, diff, az = sep_cap_diff(fit)\n",
    "print(\"Sensor diff : \",fit.shape, diff.shape, az.shape)\n",
    "ruled_out= ruled_out._append(diff)\n",
    "ruled_out= ruled_out._append(az)\n",
    "ruled_out = ruled_out[~ruled_out.index.duplicated(keep='first')]\n",
    "print(\"ruled out df : \",ruled_out.shape)\n",
    "\n",
    "fit.to_csv(dirpath/'fitting.csv',sep=';')\n",
    "ruled_out.to_csv(dirpath/'ruled_out.csv',sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'timestamps_UTC' column to datetime type\n",
    "df['timestamps_UTC'] = pd.to_datetime(df['timestamps_UTC'])\n",
    "\n",
    "# Sort the DataFrame by the 'timestamps_UTC' column\n",
    "df_sorted = df.sort_values(by='timestamps_UTC')\n",
    "\n",
    "# new_file = 'sorted_ar41_for_ulb.csv'\n",
    "\n",
    "# # Save the sorted DataFrame to a new CSV file\n",
    "# df_sorted.to_csv(repertory+new_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sorted = df\n",
    "# Select the first 100 rows\n",
    "df_subset = df_sorted.head(N)\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values_column = df_subset.isnull().sum()\n",
    "\n",
    "# Check if there are any missing values in the entire DataFrame\n",
    "any_missing_values = df_subset.isnull().values.any()\n",
    "\n",
    "total_missing_values = missing_values_column.sum()\n",
    "\n",
    "# Display the results\n",
    "print(\"Missing values in each column:\\n\", missing_values_column)\n",
    "print(\"\\nAre there any missing values in the DataFrame?\", any_missing_values)\n",
    "print(\"Nombre total de valeurs manquantes dans le DataFrame:\", total_missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_subset = df_subset.iloc[:1000]\n",
    "\n",
    "current_set = df_sub_subset\n",
    "# Interpolate missing values using linear interpolation\n",
    "df_interpolated = current_set.interpolate()\n",
    "\n",
    "# Check if there are any missing values after interpolation\n",
    "any_missing_values_after_interpolation = df_interpolated.isnull().values.any()\n",
    "\n",
    "# Display the results\n",
    "print(\"Are there any missing values in the DataFrame after interpolation?\", any_missing_values_after_interpolation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate missing values using polynomial interpolation of order 2\n",
    "df_interpolated_polynomial = current_set.interpolate(method='polynomial', order=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Original Data\n",
    "plt.scatter(range(len(current_set)), current_set['RS_E_InAirTemp_PC2'], label='Original', marker='o', color='blue', alpha=0.5)\n",
    "\n",
    "# Linear Interpolation\n",
    "# plt.plot(range(len(df_interpolated)), df_interpolated['RS_E_InAirTemp_PC2'], label='Linear Interpolation', color='green')\n",
    "\n",
    "# Polynomial Interpolation\n",
    "plt.plot(range(len(df_interpolated_polynomial)), df_interpolated_polynomial['RS_E_InAirTemp_PC2'], label='Polynomial Interpolation', color='orange')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Row number')\n",
    "plt.ylabel('RS_E_InAirTemp_PC2')\n",
    "plt.title('Comparison of Interpolations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals_linear = current_set['RS_E_InAirTemp_PC2'] - df_interpolated['RS_E_InAirTemp_PC2']\n",
    "residuals_polynomial = current_set['RS_E_InAirTemp_PC2'] - df_interpolated_polynomial['RS_E_InAirTemp_PC2']\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(range(len(current_set)), residuals_linear, label='Linear Residuals', color='green')\n",
    "plt.plot(range(len(current_set)), residuals_polynomial, label='Polynomial Residuals', color='orange')\n",
    "\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=1, label='Zero Residual')\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df['mapped_veh_id'].nunique()\n",
    "print(f'Total number of unique values: {unique_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "def plot_autocorrelation(df, column_name, lags=40):\n",
    "    \"\"\"\n",
    "    Plot autocorrelation for a specific column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the time series data.\n",
    "    - column_name (str): The name of the column for which to plot the autocorrelation.\n",
    "    - lags (int): Number of lags to include in the plot.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plot_acf(df[column_name], lags=lags)\n",
    "    plt.title(f'Autocorrelation Plot for {column_name}')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.show()\n",
    "\n",
    "selected_columns = current_set.columns[5:]\n",
    "print(selected_columns)\n",
    "\n",
    "# selected_columns = current_set.columns[6]\n",
    "for column_name in selected_columns:\n",
    "    plot_autocorrelation(current_set, column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check stationarity or non stationarity of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from 5th to 8th (index 4 to 7)\n",
    "selected_columns = current_set.columns[5:]\n",
    "\n",
    "for column_name in selected_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(current_set.index, current_set[column_name], label=column_name)\n",
    "    plt.title(f'Data Plot for {column_name}')\n",
    "    plt.xlabel('Index')  # Use 'Index' instead of 'Timestamp'\n",
    "    plt.ylabel(column_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
